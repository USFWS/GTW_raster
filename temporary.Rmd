
###Importing and Exporting Vector GIS Data in `R`

*__Credits for this section go to Jillian Deines, Michigan State University and Whalen Dillon, North Carolina State University__*

Now let's read in shapefiles. Two primary functions exist to read in .shp files: 

* `readShapeSpatial` in package `maptools` doesn't read projection information; need to set manually
* `readOGR` in package 'rgdal' reads projection information, so **we'll use this exclusively**. More information on manipulating projections in `R` will follow.

Here, we import a polygon boundary for the Colorado Plateau (CP) that has an Albers Equal Area projection, "COP_boundpoly_aea.shp" from the 'data' course subfolder. 

```{r loadSHP2}
# load shapefile by specifying folder name (dsn), and layer name (no extension!)
cp.poly <- readOGR(dsn = 'data',             # subfolder name 
                   layer = 'COP_boundpoly_aea')   # file name without extension
```

####Examine loaded shapefile

Let's now take a look at what we loaded and make a simple plot of it

```{r polyExplor}
# View description. Note the coordinate bounding box and projection info
summary(cp.poly)
# just look at projection
proj4string(cp.poly)
# make a simple plot
plot(cp.poly, axes=T, col='blue', main = "CO Plateau")
```


####Import Line and Point Shapefiles

No matter what type of vector data you are working with, all shapefiles are read in the same way we just demonstrated. Let's now load points from the "COP_Major_Cities_pt.shp" as a demonstration. *NOTE:* the shapefile has an attribute table with 47 columns/attributes.

```{r loadLinesPoints}
# load shapefile by specifying folder name (dsn), and layer name (no extension!)
cities <- readOGR(dsn = 'data', layer = 'COP_Major_Cities_pt')
# make a quick plot. note that projections need to match
par(mar=c(2,2,2,2))             # make plot margins smaller
plot(cp.poly, col='azure2')     # plot CO Plateau polygon
plot(cities, add=T,             # add city points using add=T
     col='red',                 # point color      
     pch=19,                    # point type (here, solid circles)
     cex=1.5)                   # point size
```

####Querying data of a vector (shapefile)

Let's first read a different set of shapefiles and inspect some of their components and structures.
```{r readShp}
utah.wgs84 <- readOGR(dsn = "data", layer = "utah_wgs84") # Utah border, for "pretty" plotting
deer_unit <- readOGR(dsn = "data", layer = "deerrange_UT") # Game management units

#Take a look at the game management data we loaded
summary(deer_unit)

#This tells us the characteristics of the object, as well as giving a summary of the attribute data stored in the data #table. The attribute data is stored in a slot called `@data` so if we just want to look at the data stored in the #object:
summary(deer_unit@data)
names(deer_unit) # The attribute data names

#The `@data` slot is in fact a class `data.frame` like would be most other tables loaded into `R`, while the entire #object is a Spatial Polygons Data Frame.
class(deer_unit)
class(deer_unit@data)
```

Make a basic plot with coloring based on `UName`

```{r plot deer units}
plot(deer_unit, 
     axes = TRUE, # adds the coordinate ranges to the axes
     col = deer_unit$UName, # colors the polygons based on UName
     main = "Utah Game Management Units" # adds main title to plot
     )
plot(utah.wgs84, add = TRUE) # Add the Utah border for reference
```

Use the `spplot` function from `sp` package to provide coloring and a legend based on the `UName` (unit name) attribute of the management units.

```{r spplot method}
spplot(deer_unit, c("UName"), 
       scales = list(draw = TRUE), # this adds the coordinate values to the plot
       main = "Utah Game Management Units" # adds title to map
       # ,sp.layout = list("sp.polygons", utah.wgs84) # adds Utah border to map within call to `spplot` function
       ) +
      layer(sp.polygons(utah.wgs84)) # alternative way to add layers to map; requires `latticeExtra` package
```

Querying the data in a shapefile is much the same as querying any other data frame in `R`. For example, if you want to look at the data only for the West Desert unit.
```{r query}
#Query data of interest
wd <- deer_unit[deer_unit$UName == "West Desert",]
summary(wd)
plot(wd)
plot(deer_unit, main = "West Desert Game Management Unit")
plot(utah.wgs84, add = TRUE)
plot(wd, add = TRUE, col = "red")
```

Or perhaps you just want to have a quick look at how many deer are in the Box Elder unit.
```{r query vector data value}
deer_unit@data$DEER[deer_unit@data$UName == "Box Elder"]
```

Note that these are base `R` methods for indexing. There are also several frequently used packages that have been built to help with manipulation of data as needs become more complex, e.g. `plyr`, `dplyr`, `data.table` as three well known packages.

####Convert Latitude/Longitude Spreadsheet Data to A Point Shapefile

If you have a spreadsheet of latitude and longitude data points, you can convert that to a spatialPointsDataFrame (spdf) in `R` and then write out a shapefile for future use. Here we'll use coordinate data that is in .csv format, but you could also use .xls(x) provided you use the appropriate R package to load Excel files (I'd recommend `readxl`). Generally, .csv or .txt files are faster and easier to use.

Here, we'll load lat/long presence/absence data for the species _Juniperus osteosperma_ in the juos_presab.csv spreadsheet and learn how to write out shapefiles.

```{r convertXY, echo=-1} 
# load xy data as a data frame
juos <- read.csv('data/juos_presab.csv')
# look at data structure: 
str(juos)
head(juos)
# convert dataframe to spdf by specifying long and lat column names
# format: ~ longitudeColumn + latitudeColumn
coordinates(juos) <- ~ wgs84_x + wgs84_y
# check out our new spdf object
summary(juos)
```

Note once again that our projection is undefined. Since the .csv has no associated projection information, we need to specify it. We know that the coordinates are in a WGS84 based lat/long coordinate reference system.

```{r convertXY2}
# create character vector defining the proj4 string for WGS84
WGS84.proj <- "+proj=longlat +datum=WGS84" 
# set the proj4string
proj4string(juos) <- CRS(WGS84.proj)  
# take a look
summary(juos)
```
Plot our new spatial points, coloring based on presence/absence attribute.

```{r plotxy}
# make a plot based on juos attribute column (0 or 1)
plot(juos, pch=19, cex = 0.8, col=c("cadetblue3","coral1"))
# add a simple legend
legend("topleft",                          # position in plot
       fill=c("cadetblue3","coral1"),      # match colors with plot colors   
       legend = c("0","1"),                # specify legend text
       bty='n')                            # don't use a box around the legend
```

####Write Out Shapefile

All shapefiles (points, lines, and polygons) can be written out with the `writeOGR` function in the rgdal package. Here we demonstrate with our newly created spatial point object, which we will write out to the "outData" subfolder within the module 1 data directory and call "juos_pts_wgs84.shp".

Note that we will use the ESRI shapefile driver to create a .shp file, but the 'driver' argument has many options including GeoJSON, KML, etc. Typing ogrDrivers() at your command line will give a list of available drivers.

```{r writePoints}
# write out point shapefile. 
writeOGR(obj = juos, dsn = 'data/outData', layer = 'juos_pts_wgs84',
         driver = 'ESRI Shapefile', overwrite_layer=T)
```

###Importing and Exporting Raster GIS Data in `R`

The primary package for raster work is conveniently named `raster`.

####Load a Raster

The `raster` function in the raster package is quite flexible and can be used to read and write the following filetypes (type '?writeFormats' at the command line for more information via the help file). The raster call works largely the same for all of these filetypes; here we will load a 1 km elevation file in HFA/ERDAS Imagine format (.img), "elev_1k_wgs.img", from the 'data' folder.

Note that for large rasters, the raster package loads information about the data structure (rows, columns, spatial extent, filename) but processes the data in chunks from the harddrive when needed for operations. This allows it to work with objects too large to be loaded into memory but can sometimes be slow.

```{r loadRas}  
# load raster by specifying filename with extension; extension sets format
elev1km.wgs84 <- raster("data/elev_1k_wgs.tif")
# type the name of the object to get information
elev1km.wgs84
```

Load our polygon boundary and plot, showing base `plot` and `spplot` examples.

```{r loadRas3}
# load our polygon boundary in WGS84 (see module 1.1 for loading vector files)
cp.latlong <- readOGR(dsn = 'data', layer = 'COP_boundpoly_wgs84')

# plot the raster dataset using baseplot (plot) 
plot(elev1km.wgs84, 
     col = terrain.colors(16),     # terrain.colors is a base color ramp
     main = "Elevation (m)")       # title of plot
# add our polygon boundary
plot(cp.latlong, add=T)              
```

Note that the extent is much larger than our study region; We will cover cropping and additional extent issues later on.

####Load Multiple Rasters (Stack)

The raster package can also load rasters of identical projection and extent directly into a raster stack, which can make operations on multiple rasters very efficient to execute. If projection and extent for files does not match, it needs to be modified prior to stacking rasters together.

To load monthly minimum temperature (tmin) files from WorldClim, we will:

* get a list of raster files within the 'WorldClimClip' subfolder using the `list.files` function, using regex search patterns to return files of specific extension (or name, etc.)
* load files directly into a stack using `stack`
* make a basic panel plot using `spplot`

```{r loadStack, cache=TRUE} 
#list files in working directory subfolder with extension ".bil"
rasterFiles <- list.files(path = 'data/worldClimClip',  # specify directory
                          pattern = "*tif$",         # restrict file names using regex
                          full.names=T)              # return full file path

#load all 12 rasters at once into a stack
tmin.stack <- stack(rasterFiles)
#get information; note the "nlayers" attribute
tmin.stack
#define the projection for all 12 rasters
proj4string(tmin.stack) <- CRS("+proj=longlat +datum=WGS84")
#plot rasters in the same panel
plot(tmin.stack)

##NOT RUN:
#look at files. spplot uses R's lattice package to do automatic panelling
#May take ~1.5 minutes to make full panel of 12 plots
#spplot(tmin.stack, 
#       main = "Minimum Temperature",    # plot title
#       names.attr = month.name) +       # manually set panel titles
#  layer(sp.polygons(cp.latlong))        # add boundary polygon
```

Stacks are a great way to do batch operations; for example, note that the scale on the Tmin plot is inflated by one order of magnitude. The WorldClim files are stored without decimal values to reduce files size, so to get the actual minimum temperature, we need to divide all 12 rasters by a factor of 10.

```{r modifyStack}
#divide all 12 tmin rasters by 10
tmin.stack.corrected <- tmin.stack / 10
##NOT RUN: 
#view change, note scale
#spplot(tmin.stack.corrected, main = "Minimum Temperature (C)", 
#       names.attr = month.name) + 
#  layer(sp.polygons(cp.latlong))  
```

####Write Out Raster

You can write out rasters in multiple formats (.tif, .img, etc) and multiple data types (binary, signed/unsigned integer, floating decimals) to manage file sizes, etc.

If the format arguments are omitted, `writeRaster` will infer the format from the filename extension, and will default to 'FLT4S' datatype. See ?dataType for options.

```{r writeRaster}
# write out the raster object 'cp.ras3'
writeRaster(tmin.stack.corrected[[1]], filename = 'data/outData/cpGrid_wgs84.tif', overwrite = T)
```

####END OF INTRODUCTION TO R IN GIS####


```{r eval=FALSE, include=FALSE}
# convert .Rmd script to .R file for instruction
# note .R file subsequently cleaned up for code margin of ~80 char

rmd2rscript <- function(infile,outfile){
  # read the file
  flIn <- readLines(infile)
  # identify the start of code blocks
  cdStrt <- which(grepl(flIn, pattern = "```{r*", perl = TRUE))
  # identify the end of code blocks
  cdEnd <- sapply(cdStrt, function(x){
    preidx <- which(grepl(flIn[-(1:x)], pattern = "```", perl = TRUE))[1]
    return(preidx + x)
  })
  # define an expansion function
  # strip code block indacators
  flIn[c(cdStrt, cdEnd)] <- ""
  expFun <- function(strt, End){
    strt <- strt+1
    End <- End-1
    return(strt:End)
  }
  idx <- unlist(mapply(FUN = expFun, strt = cdStrt, End = cdEnd, 
                SIMPLIFY = FALSE))
  # add comments to all lines except code blocks
  comIdx <- 1:length(flIn)
  comIdx <- comIdx[-idx]
  for(i in comIdx){
    flIn[i] <- paste("# ", flIn[i], sep = "")
  }
  # create an output file
  #nm <- strsplit(infile, split = "\\.")[[1]][1]
  flOut <- file(outfile, "w")
  for(i in 1:length(flIn)){
    cat(flIn[i], "\n", file = flOut, sep = "\t")
  }
  close(flOut)
}

infile <- 'IntroRGIS.Rmd'
outfile <- 'IntroRGIS.R'

rmd2rscript(infile, outfile)
```